# ANN Search Quick Start Guide

## ğŸš€ Quick Start (5 minutes)

### 1. Basic Usage

```python
from hypergraphrag.retrieval.ann_search import ANNSearchEngine
import numpy as np

# Create engine
engine = ANNSearchEngine(
    backend="hnsw",
    dimension=1536,
    config={"M": 16, "ef_construction": 200, "ef_search": 50}
)

# Build index
embeddings = your_embeddings  # shape: (n, 1536)
ids = your_ids  # list of hyperedge IDs
await engine.build_index(embeddings, ids)

# Search
query_embedding = your_query_embedding  # shape: (1536,)
results = await engine.search(query_embedding, top_k=10)

# Results: [(id, similarity), ...]
for hyperedge_id, similarity in results:
    print(f"{hyperedge_id}: {similarity:.4f}")
```

### 2. With LiteRetriever

```python
from hypergraphrag.retrieval.lite_retriever import LiteRetriever

config = {
    "use_ann": True,
    "ann_backend": "hnsw",
    "embedding_dim": 1536,
    "ann_config": {"M": 16, "ef_construction": 200, "ef_search": 50},
    "embedding_func": your_embedding_function
}

retriever = LiteRetriever(graph, vdb, config)
results = await retriever.retrieve("your query", top_k=10)
```

## ğŸ“Š Configuration Cheat Sheet

### Recommended Presets

```python
# ğŸƒ High Speed (5x faster, 90% accuracy)
config = {"M": 8, "ef_construction": 100, "ef_search": 20}

# âš–ï¸ Balanced (3x faster, 95% accuracy) â­ DEFAULT
config = {"M": 16, "ef_construction": 200, "ef_search": 50}

# ğŸ¯ High Accuracy (2x faster, 98% accuracy)
config = {"M": 32, "ef_construction": 400, "ef_search": 100}
```

### Parameter Guide

| Parameter | What it does | Range | Impact |
|-----------|--------------|-------|--------|
| `M` | Connections per layer | 8-32 | Higher = better accuracy, more memory |
| `ef_construction` | Build quality | 100-400 | Higher = better index, slower build |
| `ef_search` | Search quality | 20-200 | Higher = better accuracy, slower search |

## ğŸ”§ Common Tasks

### Save/Load Index

```python
# Save
engine.save_index("my_index.hnsw")

# Load
new_engine = ANNSearchEngine(backend="hnsw", dimension=1536)
new_engine.load_index("my_index.hnsw")
```

### Measure Accuracy

```python
# With LiteRetriever
metrics = await retriever.measure_ann_accuracy(test_queries, top_k=10)
print(f"Recall@10: {metrics['recall@10']:.3f}")
print(f"Speedup: {metrics['speedup']:.2f}x")
```

### Adjust Search Quality

```python
# Faster search (lower accuracy)
engine.set_search_params(ef_search=20)

# Better accuracy (slower search)
engine.set_search_params(ef_search=100)
```

## ğŸ¯ Decision Tree

```
Need ANN search?
â”‚
â”œâ”€ Dataset < 10K vectors
â”‚  â””â”€ Use exact search (fast enough)
â”‚
â”œâ”€ Dataset 10K-100K vectors
â”‚  â””â”€ Use HNSW with balanced config
â”‚
â”œâ”€ Dataset 100K-1M vectors
â”‚  â””â”€ Use HNSW with high speed config
â”‚
â””â”€ Dataset > 1M vectors
   â””â”€ Consider FAISS with GPU (if available)
```

## ğŸ“ˆ Performance Expectations

| Dataset Size | Build Time | Search Time | Speedup |
|--------------|------------|-------------|---------|
| 1K vectors | <0.1s | <0.1ms | 2x |
| 10K vectors | <1s | <0.2ms | 5x |
| 100K vectors | <10s | <0.5ms | 20x |
| 1M vectors | <2min | <1ms | 100x |

*Using balanced config on M4 MacBook Pro*

## âš ï¸ Troubleshooting

### Low Recall (<85%)

```python
# Increase ef_search
engine.set_search_params(ef_search=100)

# Or rebuild with higher M
config = {"M": 32, "ef_construction": 400, "ef_search": 100}
```

### Too Slow

```python
# Decrease ef_search
engine.set_search_params(ef_search=20)

# Or use high speed preset
config = {"M": 8, "ef_construction": 100, "ef_search": 20}
```

### Out of Memory

```python
# Reduce M
config = {"M": 8, ...}

# Or use FAISS with product quantization
config = {"index_type": "IVFPQ", "m": 8}
```

## ğŸ“š Learn More

- Full documentation: `hypergraphrag/retrieval/README_ANN_SEARCH.md`
- Test examples: `test_ann_search.py`
- Integration examples: `example_ann_search_integration.py`
- Task summary: `.kiro/specs/dynhyperrag-quality-aware/TASK_12_2_SUMMARY.md`

## ğŸ“ Best Practices

1. âœ… Start with balanced config
2. âœ… Measure accuracy on your data
3. âœ… Save index to avoid rebuilding
4. âœ… Monitor recall@k in production
5. âœ… Tune ef_search for your needs

## ğŸ’¡ Pro Tips

- **Build once, search many**: Index building is slow, searching is fast
- **Runtime tuning**: Adjust `ef_search` without rebuilding
- **Batch queries**: Use `batch_search()` for better throughput
- **Monitor accuracy**: Check recall@k periodically
- **Start conservative**: Use balanced config, then optimize

## ğŸš¦ Quick Test

```bash
# Run tests
python test_ann_search.py

# Run examples
python example_ann_search_integration.py
```

Expected output:
```
âœ… Basic ANN engine tests passed!
âœ… ANN accuracy tests passed!
âœ… Speed comparison tests passed!
âœ… LiteRetriever integration tests passed!
ğŸ‰ All ANN search tests passed!
```

---

**Ready to use ANN search in your DynHyperRAG system!** ğŸ‰
